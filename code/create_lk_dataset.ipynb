{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Young Host Stars Lightcurve Downloader\n",
    "\n",
    "In this notebook, we will use the `identify_young_stars.ipynb` file to identify young host stars and save the results as a database in `results/young_stars_below199Myr.csv`. Our goal is to determine how many of these stars have lightcurves available for download using the `lightkurve` Python library.\n",
    "\n",
    "To achieve this, we will create a new Jupyter notebook and import the necessary modules. We will then load the `young_stars_below199Myr.csv` file and loop through each star to search for its lightcurve using `lightkurve`. If a lightcurve is found, we will download it and save it to a folder for further analysis.\n",
    "\n",
    "By the end of this notebook, we will have a dataset of lightcurves for young host stars that can be used for various scientific analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightkurve as lk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from a CSV File\n",
    "\n",
    "We read data with information about the young host stars of interest from the `results/young_stars_below199Myr.csv` we generated with `identify_young_stars.ipynb` using the Nasa Exoplanet Database.\n",
    "\n",
    "We extract different star names for the same host star from our database, and by looping them we try to find a match for the name that `lightkurve` uses for the star. \n",
    "\n",
    "We generate a database with relevant information for each host star like:\n",
    "- If it has lightcurves available\n",
    "- How many of them \n",
    "- Number of lightcurves per cadence\n",
    "- Missions that retrieved lighcurves\n",
    "\n",
    "Database is saved in `results/TPF_dataframe.csv`.\n",
    "\n",
    "This can take up to half an hour to retrieve all the data for each host star, as we are looping through 247 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../results/young_stars_below_100Myr.csv'\n",
    "df = pd.read_csv(path_data, index_col=0)\n",
    "name_heads = ['hostname', 'hd_name', 'hip_name', 'tic_id', 'gaia_id']\n",
    "star_names = [list(df[name_head]) for name_head in name_heads]\n",
    "\n",
    "# Initialize DataFrame\n",
    "result_df = pd.DataFrame(columns=['Star_Name', 'TPF_Found', 'Found_Star_Name', 'Num_Results', 'Target_Name'])\n",
    "\n",
    "for j in range(len(star_names[0])):\n",
    "\n",
    "    # Initialize row dictionary\n",
    "    row_data = {}\n",
    "    \n",
    "    row_data['Star_Name'] = star_names[0][j]\n",
    "    \n",
    "    for i in range(len(star_names)):\n",
    "        star_name = star_names[i][j]\n",
    "        \n",
    "        if star_name is not np.nan:\n",
    "            tpf = lk.search_targetpixelfile(star_name)\n",
    "\n",
    "            \n",
    "            if len(tpf) > 0:\n",
    "                missions = list(set(list(tpf.table['obs_collection'])))\n",
    "                missions_str = '/'.join(missions)\n",
    "                row_data['TPF_Found'] = True\n",
    "                row_data['Mission'] = missions_str\n",
    "                row_data['Found_Star_Name'] = star_name\n",
    "                row_data['Num_Results'] = len(tpf)\n",
    "                row_data['Target_Name'] = tpf.table['target_name'][0]\n",
    "                \n",
    "                # Adding dynamic columns for exptime\n",
    "                for exptime in tpf.table['exptime']:\n",
    "                    col_name = f'exptime_{exptime:.0f}'\n",
    "                    if col_name not in result_df.columns:\n",
    "                        result_df[col_name] = 0\n",
    "                    row_data[col_name] = row_data.get(col_name, 0) + 1\n",
    "                \n",
    "                break  # Exit if TPF is found\n",
    "            else:\n",
    "                row_data['TPF_Found'] = False\n",
    "                \n",
    "    # Append the row to DataFrame\n",
    "    result_df = pd.concat([result_df, pd.DataFrame(row_data, index=[0])], ignore_index=True)\n",
    "    # make the column 'Mission' the third one\n",
    "\n",
    "\n",
    "# Replace NaNs with appropriate defaults (e.g., 0 or False)\n",
    "result_df.fillna({'TPF_Found': False, 'Found_Star_Name': 'Not Found', 'Num_Results': 0}, inplace=True)\n",
    "result_df.fillna(0, inplace=True)\n",
    "\n",
    "savefold = '../results/'\n",
    "if not os.path.exists(savefold):\n",
    "    # create the folder if it does not exist\n",
    "    os.makedirs(savefold)\n",
    "figname = f'TPF_dataframe.csv'\n",
    "savepath = savefold + figname\n",
    "result_df.to_csv(savepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "We use the dataframe we just generated to download the data. This cell can be run without running the previous on eif the dataset has already been generated. For that we retrieve the all the Target Pixel Files  (TPFs) for each host star. We use the in-built pipeline to mask the data and integrate the lightcurve.   \n",
    "\n",
    "Lightcurves are saved in `results/TPF_data` as `.fits` files and classified them by cadence by subfolder. \n",
    "\n",
    "The downloading can take up to an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder for Kepler-1663 already exists. Skipping...\n",
      "Folder for K2-33 already exists. Skipping...\n",
      "Folder for TOI-1227 already exists. Skipping...\n",
      "Folder for HD_114082 already exists. Skipping...\n",
      "Folder for HIP_67522 already exists. Skipping...\n",
      "Folder for WASP-25 already exists. Skipping...\n",
      "Folder for AU_Mic already exists. Skipping...\n",
      "Folder for V1298_Tau already exists. Skipping...\n",
      "Folder for HD_109833 already exists. Skipping...\n",
      "Folder for CoRoT-18 already exists. Skipping...\n",
      "Folder for TOI-837 already exists. Skipping...\n",
      "Folder for KOI-7913_A already exists. Skipping...\n",
      "Folder for KOI-7368 already exists. Skipping...\n",
      "Folder for DS_Tuc_A already exists. Skipping...\n",
      "Folder for Kepler-1643 already exists. Skipping...\n",
      "Folder for TOI-942 already exists. Skipping...\n",
      "Folder for CoRoT-20 already exists. Skipping...\n",
      "Folder for Kepler-1928 already exists. Skipping...\n",
      "Folder for Kepler-970 already exists. Skipping...\n",
      "Folder for K2-284 already exists. Skipping...\n",
      "Folder for TOI-251 already exists. Skipping...\n",
      "Folder for Kepler-529 already exists. Skipping...\n",
      "Folder for KOI-1783 already exists. Skipping...\n",
      "Folder for Kepler-1733 already exists. Skipping...\n",
      "Folder for Kepler-279 already exists. Skipping...\n",
      "Folder for Kepler-1903 already exists. Skipping...\n",
      "Folder for Kepler-1764 already exists. Skipping...\n",
      "Folder for Kepler-394 already exists. Skipping...\n",
      "Folder for Kepler-59 already exists. Skipping...\n",
      "Folder for Kepler-216 already exists. Skipping...\n",
      "Folder for Kepler-31 already exists. Skipping...\n",
      "Folder for Kepler-265 already exists. Skipping...\n",
      "Folder for Kepler-1762 already exists. Skipping...\n",
      "Folder for TOI-1431 already exists. Skipping...\n",
      "Folder for Kepler-1905 already exists. Skipping...\n",
      "Folder for Kepler-1126 already exists. Skipping...\n",
      "Folder for Kepler-501 already exists. Skipping...\n",
      "Folder for Kepler-51 already exists. Skipping...\n",
      "Folder for Kepler-1785 already exists. Skipping...\n",
      "Folder for Kepler-291 already exists. Skipping...\n",
      "Folder for Kepler-1884 already exists. Skipping...\n",
      "Folder for Kepler-1787 already exists. Skipping...\n",
      "Folder for Kepler-864 already exists. Skipping...\n",
      "Folder for Kepler-1866 already exists. Skipping...\n",
      "Folder for Kepler-193 already exists. Skipping...\n",
      "Folder for Kepler-366 already exists. Skipping...\n",
      "Folder for Kepler-371 already exists. Skipping...\n",
      "Folder for Kepler-347 already exists. Skipping...\n",
      "Folder for Kepler-1778 already exists. Skipping...\n",
      "Folder for Kepler-53 already exists. Skipping...\n",
      "Folder for Kepler-1875 already exists. Skipping...\n",
      "Folder for Kepler-29 already exists. Skipping...\n",
      "Folder for Kepler-377 already exists. Skipping...\n",
      "Folder for Kepler-228 already exists. Skipping...\n",
      "Kepler-1677 (Gaia DR2 2085575272147044608): Found 14 TPFs\n",
      "Downloading TPF 1/14\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pere\\Documents\\ULL\\projects\\exoplanet\\young_star_confirmed_exo\\code\\create_lk_dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pere/Documents/ULL/projects/exoplanet/young_star_confirmed_exo/code/create_lk_dataset.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Get the exposure time\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pere/Documents/ULL/projects/exoplanet/young_star_confirmed_exo/code/create_lk_dataset.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m exptime \u001b[39m=\u001b[39m tpf[i]\u001b[39m.\u001b[39mexptime\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Pere/Documents/ULL/projects/exoplanet/young_star_confirmed_exo/code/create_lk_dataset.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m match \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mstr\u001b[39m(exptime))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pere/Documents/ULL/projects/exoplanet/young_star_confirmed_exo/code/create_lk_dataset.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m number \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(match\u001b[39m.\u001b[39mgroup())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pere/Documents/ULL/projects/exoplanet/young_star_confirmed_exo/code/create_lk_dataset.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Create a folder for this exposure time within the star's folder\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "path_data = '../results/TPF_dataframe.csv'\n",
    "df = pd.read_csv(path_data)\n",
    "\n",
    "folder = '../results/TPF_data/'\n",
    "subfolders = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Check if TPF was found for this star\n",
    "    if row['TPF_Found']:\n",
    "        # Create a folder for the star\n",
    "        name = row['Star_Name']\n",
    "        \n",
    "        #join name with underscores\n",
    "        name = name.replace(\" \", \"_\")\n",
    "        star_folder = f\"{folder}{name}\"\n",
    "\n",
    "        if star_folder in subfolders:\n",
    "            print(f\"Folder for {name} already exists. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(star_folder, exist_ok=True)\n",
    "        # Search for the TPF\n",
    "        found_name = row['Found_Star_Name']\n",
    "        tpf = lk.search_targetpixelfile(row['Found_Star_Name'])\n",
    "        n_tpf = len(tpf)\n",
    "\n",
    "        print(f'{name} ({found_name})', end=': ')\n",
    "        print(f\"Found {n_tpf} TPFs\")\n",
    "        # Loop through the search result\n",
    "        for i in range(n_tpf):\n",
    "            print(f\"Downloading TPF {i+1}/{n_tpf}\", end='\\r')\n",
    "            # Get the exposure time\n",
    "            exptime = tpf[i].exptime\n",
    "            match = re.search(r'\\d+', str(exptime))\n",
    "            number = int(match.group())\n",
    "            # Create a folder for this exposure time within the star's folder\n",
    "            exptime_folder = f\"{star_folder}/exp_{number}\"\n",
    "            os.makedirs(exptime_folder, exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                tpf_file = tpf[i].download()\n",
    "                fits_hdu = tpf_file.to_lightcurve(aperture_mask=tpf_file.pipeline_mask).to_fits()\n",
    "                header = fits_hdu[0].header\n",
    "                telescope, date, object = header['TELESCOP'], header['DATE'], header['OBJECT']\n",
    "                path = f\"{exptime_folder}/{name}_{telescope}_{date}_{object}_{i}.fits\"\n",
    "                fits_hdu.writeto(path, overwrite=True)\n",
    "                \n",
    "            except lk.LightkurveError as e:\n",
    "                print(f\"Error downloading TPF for {row['Star_Name']}: {e}\")\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error downloading TPF for {row['Star_Name']}: {e}\")\n",
    "            except IndexError as e:\n",
    "                print(f\"IndexError: {e}. Skipping iteration {i}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
